# -*- coding: utf-8 -*-
"""RachelRi_Hw5

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cio7ll1lJWLXXNlGoKQJiYnCsG30-eP_
"""

### Define Libraries and other items ###
import pandas as pd
import seaborn as sns
import numpy as np
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import tree
import matplotlib.pyplot as plt
#Prevent df warning when duplicated
pd.set_option('mode.chained_assignment', None) #Supress warning since we will edit views

#Problem 1
print("Problem 1.1: load the Excel (”raw data” worksheet) data into Pandas dataframe")
df = pd.read_excel ('https://archive.ics.uci.edu/ml/machine-learning-databases/00193/CTG.xls','Raw Data') #Read file and asssign scheet
df = df.drop(['FileName' , 'Date' , 'SegFile' , 'b' , 'e' , 'LBE' , 'LB' , 'AC' , 'FM' , 'UC' , 'ALTV' , 'MLTV' , 'DL' , 'DS' , 'DP' , 'DR' , 'Width' , 'Min' , 'Nmax' , 'Nzeros' , 'Mode' , 'Mean' ,  'Variance' , 'Tendency' , 'A' , 'B' , 'C' , 'D' , 'E' , 'AD' , 'DE' , 'LD' , 'FS' , 'SUSP' , 'CLASS'], axis=1) #drop extra columns in pandas
df = df.dropna() #Delete bad data with NANS
print("DF with columns dropped")
print (df) #print df

#Problem 1.2
'''
Function that defines column "NSP_NEW" based on NSP column: If 1 then normal else abnormal
@params: Takes in each row as parameters
@returns: A numerical value for normal v abnormal: 1 normal, 0 abnormal
'''
def label_NSP(row): 
   if row['NSP'] == 1:
      return 1
   return 0
#Call function and run new NSP  
df['NSP_NEW'] = df.apply (lambda row: label_NSP(row), axis=1) #Apply lambda function on entire data frame
print("1.2 Combine NSP labels into two groups: N (normal - these labels are assigned) and Abnormal (everything else) We will use existing class 1 for normal and define class 0 for abnormal")
print("Data frame with New NSP column")
print(df) #Print Updated dataframe

print("Question 2: Use Naive Bayesian NB classifier to answer these questions:")
print("2.1 Split your set 50/50, train NB on Xtrain and predict class labels in Xtest")
X = df.iloc[:,:].values #Extract X values
le = LabelEncoder() #LB for Y
Y = le.fit_transform(df['NSP_NEW'].values) #Extract Y values
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.50) #Split test 50/50
print("X Train & Y Train for problem 2")
print(X_train,Y_train) 
print("X Test & Y Test for problem 2")
print(X_test,Y_test)
#Import Naive Multinomical bays from SKLearn
from sklearn.naive_bayes import MultinomialNB
NB_classifier = MultinomialNB().fit(X_train,Y_train) #Fit model
prediction = NB_classifier.predict(X_test) #Select prediction
dup_X_Test2 = pd.DataFrame(X_test) #Duplicate data frame
print("Predicted Class Values for problem 2") 
print(prediction) #print prediction 
dup_X_Test2["Pred"] = prediction 
print(dup_X_Test2)

## 2.2 Comparing your predicted class labels with true labels, compute a confusion matrix
'''
Stats for TP, FP, TN, FN 
@params: Data frame
@returns: df with values
'''
def stats(row):
  
  if row[5] == 1 and row["Pred"] == 1: # True Neg:
    return "TN"
  if row[5] == 0 and row["Pred"] == 1: # False Neg
    return "FN"
  if row[5] == 0 and row["Pred"] == 0: # True pos
    return "TP"
  if row[5] == 1 and row["Pred"] == 0: # False Pos
    return "FP"
  return

'''
Calculate stats
'''
## 2 Apply comparison to X test confusion matrix
#Calculate stats
dup_X_Test2["Stats"]= dup_X_Test2.apply (lambda row: stats(row), axis=1) #Apply lambda function on entire data frame
given_classifier_stats_list = dup_X_Test2['Stats'].value_counts()
FN = given_classifier_stats_list[0] #extact false negative
FP = given_classifier_stats_list[1] #extract false positive
TN =  given_classifier_stats_list[2] #extract true negative
TP = given_classifier_stats_list[3] #Extract true positive
accuracy = (TP+TN) / (TP+TN+FP+FN) #Calculate accuracy
TPR = TP/(TP + FN) #Calculate true positive rate
TNR = TN/(TN + FP) #Calculate true negative rate
print("2.2 What is the accuracy?") #Print info
print(accuracy)
print("2.3 Compute confusion matrix") #Compute confusion matrix
print("TP FP TN FN Accuracy TPR TNR")
print(TP, FP, TN , FN ,accuracy, TPR, TNR)

#Problem 3
#Import decision tree

#Reset dataframe
df = df.sample(frac=1) 
X = df.iloc[:,:].values #Extract X values
le = LabelEncoder() #Integrate LE
Y = le.fit_transform(df['NSP_NEW'].values) #Extract Y values
X_train,X_test,Y_train,Y_test=train_test_split(X, Y,test_size=0.5) #Split test 50/50
tree_classifier = tree.DecisionTreeClassifier()
tree_classifier = tree_classifier.fit(X_train, Y_train) #Classifiers
prediction = tree_classifier.predict(X_test) #Create prediction
error_rate = np.mean(prediction != Y_test) #Get error rate
print("3.1 Split your set 50/50, train NB on Xtrain and predict class labels in Xtest")
print("X Train & Y Train for problem 3")
print(X_train,Y_train) 
print("X Test & Y Test for problem 3")
print(X_test,Y_test)
print("Predicted Class Values for problem 3")
dup_X_Test3 = pd.DataFrame(X_test)
dup_X_Test3["Pred"] = prediction
print(prediction)

## 3.2 Comparing your predicted class labels with true labels, compute a confusion matrix
'''
Stats for TP, FP, TN, FN 
@params: Data frame
@returns: df with values
'''
def stats3(row):
  
  if row[5] == 1 and row["Pred"] == 1: # True Neg:
    return "TN"
  if row[5] == 0 and row["Pred"] == 1: # False Neg
    return "FN"
  if row[5] == 0 and row["Pred"] == 0: # True pos
    return "TP"
  if row[5] == 1 and row["Pred"] == 0: # False Pos
    return "FP"
  return 

## 3.3 Apply comparison to X test confusion matrix
dup_X_Test3["Stats"]= dup_X_Test3.apply(lambda row: stats3(row), axis=1) #Apply lambda function on entire data frame
print(dup_X_Test3["Stats"])
given_classifier_stats_list3 = dup_X_Test3['Stats'].value_counts()
print(given_classifier_stats_list3)
TN = given_classifier_stats_list4["TN"]
FN = 0 #classifier memorized entire data set
TP = given_classifier_stats_list4["TP"]
FP = 0 #classifier memorized entire data set

accuracy = (TP+TN) / (TP+TN+FP+FN) #Calculate accuracy
TPR = TP/(TP + FN) #Calculate true positive rate
TNR = TN/(TN + FP) #Calculate true negative rate
print("3.2 What is the accuracy?") #Print info
print(accuracy)
print("3.3 Compute confusion matrix") #Compute confusion matrix
print("TP FP TN FN Accuracy TPR TNR")
print(TP, FP, TN , FN ,accuracy, TPR, TNR)
print("Note: The tree classifier memorized entire tree and we got accuracy of 100%")

#Problem 4

print("Question 4:Use Random Forest Tree to answer these questions::")
print("4.1 Split your set 50/50, train NB on Xtrain and predict class labels in Xtest")
labels = []
values = []
print("4.1 Take N = 1, . . . , 10 and d = 1, 2, . . . , 5. For each value of N and d, split your data into Xtrain and Xtest, construct a random tree classifier")
for n in range(1,11):  #iterate from 1 to 10
  for k in range(1,6): #Iterate from 1 to 5
    df = df.sample(frac=1) #reset data frame
    X = df.iloc[:,:].values #extract X values
    le = LabelEncoder() #extract label encoder
    Y = le.fit_transform(df['NSP_NEW'].values) #extract y axis
    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.50) #Split test 50/50
    best = float('inf') #determine best error rate location
    bestn = 0 #set as 0
    bestk = 0 #set as 0
    model = RandomForestClassifier(n_estimators = n, max_depth =k,criterion ='entropy') #model random forest based on info
    model.fit (X_train,Y_train) #fit on x train and y train
    prediction = model.predict(X_test) #select prediction
    error_rate = np.mean(prediction != Y_test) #calculate error rate
    values.append(error_rate) #append error rates for chart
    print("Error Rate for n = ", n, " and k = ", k) #print info
    print(error_rate)
    if error_rate < best: #select best
      best = error_rate
      bestn = n
      bestk = k


plt.plot(values)

plt.show()
print("BEST ERROR RATE IS" ,best, "AT: N =", bestn ,"AND I  =",bestk)

## 4.2 Comparing your predicted class labels with true labels, compute a confusion matrix
'''
Stats for TP, FP, TN, FN 
@params: Data frame
@returns: df with values
'''
def stats3(row):
  
  if row[5] == 1 and row["Pred"] == 1: # True Neg:
    return "TN"
  if row[5] == 0 and row["Pred"] == 1: # False Neg
    return "FN"
  if row[5] == 0 and row["Pred"] == 0: # True pos
    return "TP"
  if row[5] == 1 and row["Pred"] == 0: # False Pos
    return "FP"
  return 

## 4.3 Apply comparison to X test confusion matrix
print("4.3 Computed confusion matrix as given_classifier stats column") #Print info
dup_X_Test4["Stats"]= dup_X_Test4.apply(lambda row: stats3(row), axis=1) #Apply lambda function on entire data frame
given_classifier_stats_list4 = dup_X_Test4['Stats'].value_counts()
print(given_classifier_stats_list4)
TN = given_classifier_stats_list4["TN"]
FN = 0 #classifier memorized entire data set
TP = given_classifier_stats_list4["TP"]
FP = 0 #classifier memorized entire data set
accuracy = (TP+TN) / (TP+TN+FP+FN) #Calculate accuracy
TPR = TP/(TP + FN) #Calculate true positive rate
TNR = TN/(TN + FP) #Calculate true negative rate
print("4.2 What is the accuracy?") #Print info
print(accuracy)
print("4.4 Compute confusion matrix") #Compute confusion matrix
print("TP FP TN FN Accuracy TPR TNR")
print(TP, FP, TN , FN ,accuracy, TPR, TNR)
print("Note: The tree classifier memorized entire tree and we got accuracy of 100%")

print("Problem 5")
print("Model TP FP TN FN Accuracy TPR TNR")
print("NB")
print(" 38 1881 43 794 7% 5% 18%")
print("Decision Tree")
print("219 0 844 0 100% 100% 100%")
print("Random Forest")
print("219 0 844 0 100% 100% 100%")